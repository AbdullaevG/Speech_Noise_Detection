{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f81e8073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install panns_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ee49aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import panns_inference\n",
    "from panns_inference import AudioTagging, SoundEventDetection, labels\n",
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cb92d555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600.0, 6400.0)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32_000 * 0.05, 32_000 * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "840b5e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def is_laugh_on_frame(lst: list):\n",
    "    return 1 if np.sum(lst) > 0 else 0\n",
    "is_laugh_on_frame([0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "08413961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: C:\\Users\\asus/panns_data/Cnn14_DecisionLevelMax.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\anaconda3\\lib\\site-packages\\torchlibrosa\\stft.py:193: FutureWarning: Pass size=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  fft_window = librosa.util.pad_center(fft_window, n_fft)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU.\n"
     ]
    }
   ],
   "source": [
    "sed = SoundEventDetection(checkpoint_path=None, device='cpu')\n",
    "LAUGHTER_CLASSES_IDX = range(16, 22)\n",
    "ROW_DATA_ROOT =  \"../rowdata/\"\n",
    "CSV_FILE_PATH = \"targets.csv\"\n",
    "SR = 32_000\n",
    "COEF = 20\n",
    "HOP_LEN = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "fc196986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_class_idx(lst: list):\n",
    "    \"\"\"\n",
    "    Change multiclass classification result in binary one: assign 1 for laugh classes \n",
    "    and 0 for all others.\n",
    "    \"\"\"\n",
    "    for idx, item in enumerate(lst):\n",
    "        if item in LAUGHTER_CLASSES_IDX:\n",
    "            lst[idx] = 1\n",
    "        else:\n",
    "            lst[idx] = 0\n",
    "\n",
    "is_laugh_on_frame = lambda lst: 1 if np.sum(lst) > 0 else 0\n",
    "\n",
    "def get_targets(row_data_root=ROW_DATA_ROOT):\n",
    "    \"\"\"\n",
    "    Get targets for frames for audios in the root folder.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_files = []\n",
    "    targets = []\n",
    "    folder_names = os.listdir(ROW_DATA_ROOT)\n",
    "    \n",
    "    for folder_name in folder_names:\n",
    "\n",
    "        audio_files = glob.glob(dataroot + folder_name + \"/*\")\n",
    "        all_files.extend(audio_files)\n",
    "        for file in audio_files:\n",
    "            (audio, _) = librosa.core.load(file, sr=SR)\n",
    "            audio = audio[None, :]  # (batch_size, segment_samples)\n",
    "\n",
    "            framewise_output = sed.inference(audio)\n",
    "            result = np.argmax(framewise_output[0], axis = 1)\n",
    "            change_class_idx(result)\n",
    "            result = [is_laugh_on_frame(result[i:i+COEF]) for i in range(0, len(result)-1, HOP_LEN)]\n",
    "            targets.append(result)\n",
    "\n",
    "    df = pd.DataFrame({\"files\": all_files, \"target\": targets})\n",
    "    df.to_csv(\"targets.csv\")\n",
    "    return all_files, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6a24417e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_files, targets = get_targets(ROW_DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4b665754",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"files\": all_files, \"target\": targets})\n",
    "df.to_csv(\"targets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d615b6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>../rowdata/laughter\\FCrKwdNk73Q_470.wav</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>../rowdata/laughter\\FDc-S1vzamg_160.wav</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>../rowdata/laughter\\FDCETc0FXq4_10.wav</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>../rowdata/laughter\\FDlnh1ITHFo_10.wav</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>../rowdata/laughter\\F_xLpdD1z88_10.wav</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       files  \\\n",
       "125  ../rowdata/laughter\\FCrKwdNk73Q_470.wav   \n",
       "126  ../rowdata/laughter\\FDc-S1vzamg_160.wav   \n",
       "127   ../rowdata/laughter\\FDCETc0FXq4_10.wav   \n",
       "128   ../rowdata/laughter\\FDlnh1ITHFo_10.wav   \n",
       "129   ../rowdata/laughter\\F_xLpdD1z88_10.wav   \n",
       "\n",
       "                                                target  \n",
       "125  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "126  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "127  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "128  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "129  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a0bb8151",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMES_DATA_PATH = './frames_data/'\n",
    "WIN_LEN = int(SR * 0.2)\n",
    "HOP = int(SR * 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a75aaa16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conversation\\\\-31gkaJsxIc_3054414', '0']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = files[0].split(\"/\")[-1][:-4] + str(np.random.randint(0, 100000)) + \"###\" + str(0)\n",
    "s.split(\"###\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fed83bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'34141'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6e9a452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "10f1108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tensor_files_mod(csv_path, save_folder=FRAMES_DATA_PATH, \n",
    "                           win_len=WIN_LEN, hop_len=HOP_LEN):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    files, targets = df.files.values, df.target.values\n",
    "    for i, file in enumerate(files):      \n",
    "        aud, sr = librosa.load(file, sr = None)\n",
    "        \n",
    "        if aud.shape[0] > 320_000:\n",
    "            aud = aud[:320_000]\n",
    "                         \n",
    "        aud_idx = 0\n",
    "        target = targets[i]\n",
    "        \n",
    "        for j in range(len(target)):\n",
    "            temp_len = len(aud[aud_idx:aud_idx + win_len])\n",
    "            file_name = save_folder + file.split(\"\\\\\")[-1][:-4] + str(np.random.randint(0, 100000)) + \"###\" + str(target[j])\n",
    "            \n",
    "            if temp_len < 6400:\n",
    "                pad_len = 6400 - temp_len\n",
    "                temp_aud = np.pad(aud, pad_len, mode = \"reflect\")[pad_len:]\n",
    "                torch.save(torch.tensor(temp_aud[aud_idx:aud_idx + win_len], dtype = torch.float32), \n",
    "                           file_name + \".pt\")\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                torch.save(torch.tensor(aud[aud_idx:aud_idx + win_len], dtype = torch.float32), \n",
    "                          file_name + \".pt\")\n",
    "                \n",
    "            aud_idx += hop_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ad087125",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tensor_files_mod(all_files[-10:], targets[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2db4b901",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp_aud' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-189-6b62cf9d93d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtemp_aud\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'temp_aud' is not defined"
     ]
    }
   ],
   "source": [
    "temp_aud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1657b34a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
